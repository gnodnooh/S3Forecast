{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook creates data chunks to facilitate HTCondor processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tools import loadmat, multi_equal, save_hdf, climdictToDf, split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global climate drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/chtc_in/dfPredGlob.hdf is saved.\n"
     ]
    }
   ],
   "source": [
    "# Load climate data\n",
    "#TODO: UPDATE FROM RAW DATA\n",
    "dictdata = loadmat(os.path.join('data', 'lscidx.mat'))\n",
    "for k in list(dictdata.keys()):\n",
    "    if not k.endswith('Linr'):\n",
    "        dictdata.pop(k)\n",
    "for k in list(dictdata.keys()):\n",
    "    dictdata[k.replace('Linr', '')] = dictdata.pop(k)\n",
    "dfPredGlob = climdictToDf(dictdata, length='short')\n",
    "dfPredGlob.columns = ['amo', 'nao', 'oni', 'pdo']\n",
    "# Save reference data (dfPredGlob)\n",
    "filn = './data/chtc_in/dfPredGlob.hdf'\n",
    "save_hdf(filn, dfPredGlob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAND Dams: Streamflow, Soil Moisture, and Snowfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dam Inflow data from SUTD\n",
    "dfFlowDams = pd.read_hdf('./data/dfFlowDams.hdf')\n",
    "ind_dams = np.load('./data/ind_dams.npz')['ind_dams']\n",
    "# Load ERA40 swvl data\n",
    "dfSwvlDams = pd.read_hdf('./data/dfSwvlDams.hdf')\n",
    "# Load WFD snowfall data\n",
    "dfSnowDams = pd.read_hdf('./data/dfSnowDams.hdf')\n",
    "# Validate order of dam ID\n",
    "multi_equal([dfFlowDams.columns,ind_dams[0,:],dfSwvlDams.columns, dfSnowDams.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of divison\n",
    "ndivDams = 1593\n",
    "listDams = list(split(list(dfFlowDams.columns), ndivDams))\n",
    "\n",
    "# Creat data chunks with multi-index\n",
    "for i in range(ndivDams):\n",
    "    # Create emtpy Series and DataFrame\n",
    "    predList1 = ['flow']\n",
    "    predList2 = ['flow', 'swvl', 'snow']\n",
    "    mcols1 = pd.MultiIndex.from_product([listDams[i], predList1], names=['point_no', ''])\n",
    "    dfPredLocl1 = pd.DataFrame(index = dfFlowDams.index, columns=mcols1)\n",
    "    mcols2 = pd.MultiIndex.from_product([listDams[i], predList2], names=['point_no', ''])\n",
    "    dfPredLocl2 = pd.DataFrame(index = dfFlowDams.index, columns=mcols2)\n",
    "    \n",
    "    # Assign data to each point\n",
    "    for j in listDams[i]:\n",
    "        dfTemp1 = dfFlowDams[j].copy()\n",
    "        dfTemp1.columns = predList1\n",
    "        dfPredLocl1[j] = dfTemp1\n",
    "        dfTemp2 = pd.concat([dfFlowDams[j], dfSwvlDams[j], dfSnowDams[j]], axis=1)\n",
    "        dfTemp2.columns = predList2\n",
    "        dfPredLocl2[j] = dfTemp2\n",
    "        \n",
    "    # Save as HDF format\n",
    "    save_hdf('./data/chtc_in/dfFlowDams{:d}.hdf'.format(i), dfFlowDams[listDams[i]], set_print=False)\n",
    "    save_hdf('./data/chtc_in/dfPredDamsLocl{:d}.hdf'.format(i), dfPredLocl2, set_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
